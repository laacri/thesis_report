% CLIP model paper
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

% GEO-Bench paper
@article{lacoste2023geo,
  title={Geo-bench: Toward foundation models for earth monitoring},
  author={Lacoste, Alexandre and Lehmann, Nils and Rodriguez, Pau and Sherwin, Evan and Kerner, Hannah and L{\"u}tjens, Bj{\"o}rn and Irvin, Jeremy and Dao, David and Alemohammad, Hamed and Drouin, Alexandre and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={51080--51093},
  year={2023}
}

% RemoteCLIP model paper
@article{liu2024remoteclip,
  title={Remoteclip: A vision language foundation model for remote sensing},
  author={Liu, Fan and Chen, Delong and Guan, Zhangqingyun and Zhou, Xiaocong and Zhu, Jiale and Ye, Qiaolin and Fu, Liyong and Zhou, Jun},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

% GeoRSCLIP model paper
@article{zhang2024rs5m,
  title={RS5M and GeoRSCLIP: A large scale vision-language dataset and a large vision-language model for remote sensing},
  author={Zhang, Zilun and Zhao, Tiancheng and Guo, Yulong and Yin, Jianwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

% EuroSAT dataset
@article{helber2019eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={12},
  number={7},
  pages={2217--2226},
  year={2019},
  publisher={IEEE}
}

% SkyScript dataset paper
@inproceedings{wang2024skyscript,
  title={Skyscript: A large and semantically diverse vision-language dataset for remote sensing},
  author={Wang, Zhecheng and Prabha, Rajanie and Huang, Tianyuan and Wu, Jiajun and Rajagopal, Ram},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={5805--5813},
  year={2024}
}%number={6},


% ChatEarthNet dataset paper
@article{yuan2024chatearthnet,
  title={Chatearthnet: A global-scale, high-quality image-text dataset for remote sensing},
  author={Yuan, Zhenghang and Xiong, Zhitong and Mou, Lichao and Zhu, Xiao Xiang},
  journal={arXiv preprint arXiv:2402.11325},
  year={2024}
}

% DOTA dataset paper
@misc{xia2019dotalargescaledatasetobject,
      title={DOTA: A Large-scale Dataset for Object Detection in Aerial Images}, 
      author={Gui-Song Xia and Xiang Bai and Jian Ding and Zhen Zhu and Serge Belongie and Jiebo Luo and Mihai Datcu and Marcello Pelillo and Liangpei Zhang},
      year={2019},
      eprint={1711.10398},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.10398}, 
}


% ...

% CLIP - First mention of InfoNCE loss
@article{sohn2016improved,
  title={Improved deep metric learning with multi-class n-pair loss objective},
  author={Sohn, Kihyuk},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

% CLIP - Popularization of InfoNCE loss
@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

% CLIP - ResNet-50
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

% CLIP - ResNet-50 improvement
@inproceedings{he2019bag,
  title={Bag of tricks for image classification with convolutional neural networks},
  author={He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={558--567},
  year={2019}
}

% CLIP - ResNet-50 improvement 2
@inproceedings{zhang2019making,
  title={Making convolutional networks shift-invariant again},
  author={Zhang, Richard},
  booktitle={International conference on machine learning},
  pages={7324--7334},
  year={2019},
  organization={PMLR}
}

% CLIP - ViT
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

% CLIP - Transformer
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% CLIP - Transformer language modifications
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

% CLIP - zero shot task
@inproceedings{lampert2009learning,
  title={Learning to detect unseen object classes by between-class attribute transfer},
  author={Lampert, Christoph H and Nickisch, Hannes and Harmeling, Stefan},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={951--958},
  year={2009},
  organization={IEEE}
}

% DALL-E
@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

% Stable Diffusion
@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

% ViT vs ResNets 1
@article{tuli2021convolutional,
  title={Are convolutional neural networks or transformers more like human vision?},
  author={Tuli, Shikhar and Dasgupta, Ishita and Grant, Erin and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2105.07197},
  year={2021}
}
%ViT vs ResNets 2
@article{deininger2022comparative,
  title={A comparative study between vision transformers and CNNs in digital pathology},
  author={Deininger, Luca and Stimpel, Bernhard and Yuce, Anil and Abbasi-Sureshjani, Samaneh and Sch{\"o}nenberger, Simon and Ocampo, Paolo and Korski, Konstanty and Gaire, Fabien},
  journal={arXiv preprint arXiv:2206.00389},
  year={2022}
}
% ViT vs ResNets 3
@article{hutten2022vision,
  title={Vision transformer in industrial visual inspection},
  author={H{\"u}tten, Nils and Meyes, Richard and Meisen, Tobias},
  journal={Applied Sciences},
  volume={12},
  number={23},
  pages={11981},
  year={2022},
  publisher={MDPI}
}
% ViTs vs ResNets 4
@article{liu2024multivariate,
  title={Multivariate image processing in minerals engineering with vision transformers},
  author={Liu, Xiu and Aldrich, Chris},
  journal={Minerals Engineering},
  volume={208},
  pages={108599},
  year={2024},
  publisher={Elsevier}
}
% ViTs vs ResNets 5
@article{wang2022hyperspectral,
  title={A hyperspectral image classification method based on adaptive spectral spatial kernel combined with improved vision transformer},
  author={Wang, Aili and Xing, Shuang and Zhao, Yan and Wu, Haibin and Iwahori, Yuji},
  journal={Remote Sensing},
  volume={14},
  number={15},
  pages={3705},
  year={2022},
  publisher={MDPI}
}


% CLIP and negation
@article{quantmeyer2024and,
  title={How and where does CLIP process negation?},
  author={Quantmeyer, Vincent and Mosteiro, Pablo and Gatt, Albert},
  journal={arXiv preprint arXiv:2407.10488},
  year={2024}
}

% Multilabel CLIP techniques
@article{guo2024multimodal,
  title={Multimodal Multilabel Classification by CLIP},
  author={Guo, Yanming},
  journal={arXiv preprint arXiv:2406.16141},
  year={2024}
}


% Normalization in DL Medium's blogpost for satellite images
@unknown{unknown,
    author = {Oman Kadunc, Nika and Peressutti, Devis and Vesel, Nejc and Batic, Matej and Verbič, Sara and Lukšič, Žiga and Aleksandrov, Matej},
    year = {2022},
    month = {09},
    pages = {},
    title = {How To Normalize Satellite Images For Deep Learning}
}



% LoRA method paper
@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}